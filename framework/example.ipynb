{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "\n",
    "from utils import *\n",
    "from solvers import EPOSolver, LinearScalarizationSolver\n",
    "from models import *\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pygmo as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/powerp.csv', sep=';', decimal=',')\n",
    "y = data[['PE']]\n",
    "X = data.drop('PE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "scaler = StandardScaler()\n",
    "seed = 1234\n",
    "set_seed(seed)\n",
    "set_logger()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Usando device = ', device)\n",
    "\n",
    "hnet = POPI_hyper(input_target=4, target_hidden_dim=4, target_hidden_size=100).to(device)\n",
    "net = POPI_target(input_target=4, target_hidden_dim=4, target_hidden_size=100).to(device)\n",
    "\n",
    "# ---------\n",
    "# Losses\n",
    "# ---------\n",
    "\n",
    "loss1 = AIW_loss()\n",
    "loss2 = PICP_alpha_loss()\n",
    "\n",
    "\n",
    "lr = 0.0005\n",
    "wd = 0.\n",
    "optimizer = torch.optim.Adam(hnet.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# ------\n",
    "# solver\n",
    "# ------\n",
    "\n",
    "solvers = dict(ls=LinearScalarizationSolver, epo=EPOSolver)\n",
    "\n",
    "solver_type = 'ls'\n",
    "solver_method = solvers[solver_type]\n",
    "if solver_type == 'epo':\n",
    "    solver = solver_method(n_tasks=2, n_params=count_parameters(hnet))\n",
    "else:\n",
    "    # ls\n",
    "    solver = solver_method(n_tasks=2)\n",
    "\n",
    "# ------\n",
    "# data\n",
    "# ------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_val = scaler.transform(y_val)\n",
    "y_test = scaler.transform(y_test)\n",
    "\n",
    "train_features = torch.Tensor(X_train)\n",
    "train_targets = torch.Tensor(y_train)\n",
    "val_features = torch.Tensor(X_val)\n",
    "val_targets = torch.Tensor(y_val)\n",
    "test_features = torch.Tensor(X_test)\n",
    "test_targets = torch.Tensor(y_test)\n",
    "train_ds = TensorDataset(train_features, train_targets)\n",
    "val_ds = TensorDataset(val_features, val_targets)\n",
    "test_ds = TensorDataset(test_features, test_targets)\n",
    "\n",
    "bs = 1500\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=len(val_ds), shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=len(test_ds), shuffle=True)\n",
    "\n",
    "n_rays = 200\n",
    "min_angle = 1e-3\n",
    "max_angle = np.pi / 2 - 1e-3\n",
    "test_rays = circle_points(n_rays, min_angle=min_angle, max_angle=max_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = dict()\n",
    "test_results = dict()\n",
    "out_dir=\"outputs_PowerP\"\n",
    "\n",
    "no_val_eval = False\n",
    "full_test = True\n",
    "eval_every = 50\n",
    "alpha=0.25\n",
    "\n",
    "best_hv = -1\n",
    "last_eval = -1\n",
    "for epoch in range(0,12000):\n",
    "    ###### Training ######\n",
    "    \n",
    "    for x_tr, y_tr in train_loader:\n",
    "        hnet.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_tr = x_tr.to(device)\n",
    "        y_tr  = y_tr.to(device)\n",
    "        \n",
    "        if alpha > 0:\n",
    "            ray = np.random.dirichlet((alpha, alpha), 1)\n",
    "            ray = torch.from_numpy(ray.astype(np.float32).flatten()).to(device)\n",
    "        else:\n",
    "            alpha = torch.empty(1, ).uniform_(0., 1.)\n",
    "            ray = torch.tensor([alpha.item(), 1 - alpha.item()]).to(device)\n",
    "        \n",
    "        weights = hnet(ray)\n",
    "        low, up = net(x_tr, weights)\n",
    "        \n",
    "        p_int = torch.cat((low, up), axis=1)\n",
    "        l1 = loss1(p_int, y_tr[:, [0]])\n",
    "        l2 = loss2(p_int, y_tr[:, [0]])\n",
    "        losses = torch.stack((l1, l2))\n",
    "        \n",
    "        ray = ray.squeeze(0)\n",
    "        loss = solver(losses, ray, list(hnet.parameters()))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    ###### HV Validation ######\n",
    "    if (epoch + 1) >= 5000:\n",
    "        if (epoch + 1) % eval_every == 0:\n",
    "            last_eval = epoch\n",
    "            if not no_val_eval:\n",
    "                epoch_results, hv = evaluate(hypernet=hnet, targetnet=net, loader=val_loader, rays=test_rays, device=device)\n",
    "                val_results[f'epoch_{epoch + 1}'] = epoch_results\n",
    "                if hv > best_hv:\n",
    "                    torch.save(hnet.state_dict(), 'best_model_hn_main.pt')\n",
    "                    best_hv = hv\n",
    "                    best_dict = epoch_results\n",
    "                    best_epoch = (epoch + 1)\n",
    "                print('Epoch: ', epoch+1, 'Best hv:', best_hv, 'in epoch', best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(out_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(Path(out_dir) / \"val_results.json\", \"w\") as file:\n",
    "    json.dump(val_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Test PIs #####\n",
    "\n",
    "PINPS = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "hnet.load_state_dict(torch.load('best_model_hn_main.pt'))\n",
    "for pinp in PINPS:\n",
    "    test_epoch_results = test(hypernet=hnet, targetnet=net, loader=test_loader, val_dict=best_dict, PINP=pinp, rays=test_rays,device=device)\n",
    "    test_results[f'PredInt_{pinp*100}'] = test_epoch_results\n",
    "with open(Path(out_dir) / \"test_results.json\", \"w\") as file:\n",
    "    json.dump(test_results, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "649709957eb6853bcf4063ba6c867e814179cef039ca7aed1cccbb5c501d2df5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
